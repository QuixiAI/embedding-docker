services:
  embeddings:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.8
    container_name: embeddings_server
    platform: linux/amd64
    command:
      - --model-id
      - ${EMBEDDING_MODEL_ID:-unsloth/embeddinggemma-300m}
      - --dtype
      - float32
    environment:
      EMBEDDING_MODEL_ID: ${EMBEDDING_MODEL_ID:-unsloth/embeddinggemma-300m}
      EMBEDDING_DIMENSION: ${EMBEDDING_DIMENSION:-768}
    ports:
      - "8080:80"
    volumes:
      - embeddings_cache:/data
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -sf http://localhost:80/v1/embeddings \
            -H 'Content-Type: application/json' \
            -d '{\"model\":\"${EMBEDDING_MODEL_ID:-unsloth/embeddinggemma-300m}\",\"input\":\"hello\"}' \
            | grep -q '\"embedding\"'"
        ]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 90s

volumes:
  embeddings_cache:
